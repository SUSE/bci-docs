[{"id":0,"href":"/bci-docs/guides/adding-users/","title":"Adding Users to SLE BCI Micro and Minimal","parent":"Guides","content":" This guide will demonstrate how to add users to the SLE BCI Micro and SLE BCI Minimal images, without having the useradd binary installed.\nBackground The SLE BCI Micro and Minimal images are tailored towards providing a small footprint and thus do not ship the useradd binary. While this reduces the image size, creating new users inside containers based on BCI Micro or Minimal involves a few additional steps.\nSwitch to using the BusyBox SLE BCI SLE BCI Minimal and SLE BCI Micro are lightweight deployment images without a package manager and tailored for specific use cases. If you do not require a package manager in your final image and additionally:\nyou do not need rpm\nyour application runs with POSIX sh and not just Bash\nthen consider using the SLE BCI BusyBox image instead. It is even smaller than SLE BCI Micro and ships the BusyBox implementation of useradd. Adding a new user in BusyBox is straightforward:\nFROM registry.suse.com/bci/bci-busybox:15.4 ARG user # add -H if /home/$user shall not be created RUN adduser -D $user USER $user This container can be built using your favorite container runtime as follows: Docker docker build --build-arg user=rancher . Podman buildah bud --layers --build-arg user=rancher . nerdctl nerdctl build --build-arg user=rancher . Using the Base Container to create the User Account We can utilize a multistage build to create the user in a container that provides the useradd binary and then copy all necessary files into SLE BCI Micro or SLE BCI Minimal. This is achieved using the following Dockerfile:\nFROM registry.suse.com/bci/bci-base:15.4 as useradder ARG user # omit -m if you don\u0026#39;t want /home/$user to be created RUN useradd -m $user FROM registry.suse.com/bci/bci-micro:15.4 ARG user COPY --from=useradder /etc/passwd /etc/passwd COPY --from=useradder /etc/group /etc/group COPY --from=useradder /etc/shadow /etc/shadow # subgid \u0026amp; subuid are rarely necessary in containers # COPY --from=useradder /etc/subgid /etc/subgid # COPY --from=useradder /etc/subuid /etc/subuid # some applications will send your user emails, in case yours does that, # uncomment the following line # COPY --from=useradder /var/spool/mail/$user /var/spool/mail/$user # only include this if you kept the -m flag to useradd COPY --from=useradder /home/$user /home/$user USER $user # remaining build / copy instructions go here Build your container image using your favorite container runtime using the --build-arg parameter as in Switch to using the BusyBox SLE BCI.\nUsing BusyBox to create the User Account We can leverage the adduser implementation from BusyBox to create new users in SLE BCI Minimal, by installing BusyBox inside the Minimal image and then executing its adduser. This will not work in the Micro image as it lacks rpm to install BusyBox.\nThis approach will leave two rpm files inside a layer of your final container image, thereby making it slightly bigger than necessary. Consider squashing the layers to remove this overhead.\nWe utilize the SLE BCI Base container once again to download the rpms of BusyBox and libsepol1 (a dependency of BusyBox), copy both rpms into the Minimal image, add the user and remove both packages afterwards:\nFROM registry.suse.com/bci/bci-base:15.4 as downloader RUN zypper download busybox libsepol1 FROM registry.suse.com/bci/bci-minimal:15.4 ARG user ARG arch=x86_64 COPY --from=downloader /var/cache/zypp/packages/SLE_BCI/$arch/*rpm /tmp/ RUN rpm -i /tmp/libsepol1*rpm \u0026amp;\u0026amp; rpm -i /tmp/busybox*rpm \u0026amp;\u0026amp; \\ busybox adduser -D $user \u0026amp;\u0026amp; \\ rpm -e busybox \u0026amp;\u0026amp; rpm -e libsepol1 \u0026amp;\u0026amp; rm -rf /tmp/*rpm USER $user Building this container image requires the additional build argument arch when building on non-x86_64 systems. We also squash the layers, if supported by the container runtime. Currently nerdctl does not support squashing and Docker requires to be launched with experimental features enabled.\nDocker docker build --build-arg user=rancher \\ --build-arg arch=$(uname -m) \\ --squash . Podman buildah bud --build-arg user=rancher \\ --build-arg arch=$(uname -m) \\ --squash . nerdctl nerdctl build --build-arg user=rancher \\ --build-arg arch=$(uname -m) . ","description":"This guide will demonstrate how to add users to the SLE BCI Micro and SLE BCI Minimal images, without having the useradd binary installed.\nBackground The SLE BCI Micro and Minimal images are tailored towards providing a small footprint and thus do not ship the useradd binary. While this reduces the image size, creating new users inside containers based on BCI Micro or Minimal involves a few additional steps."},{"id":1,"href":"/bci-docs/documentation/general-purpose-bci/","title":"BCI-Base, BCI-Minimal, BCI-Micro, and BCI-BusyBox","parent":"Documentations","content":" SUSE offers several general-purpose SLE Base Container Images that are intended as deployment targets or as foundations for creating customized images: BCI-Base, BCI-Minimal, BCI-Micro, and BCI-BusyBox. These images share the common SLES base, and none of them ship with a specific language or an application stack. All images feature the RPM database (even if the specific image does not include the RPM package manager) that can be used to verify the provenance of every file in the image. Each image includes the SLES certificate bundle, which allows the deployed applications to use the system’s certificates to verify TLS connections.\nQuick overview The table below provides a quick overview of the differences between BCI-Base, BCI-Minimal, BCI-Micro, and BCI-BusyBox.\nBCI-Base and BCI-Init: When you need flexibility This SLE BCI comes with the Zypper package manager and a free SLE-BCI repository. This allows you to install software available in the repository and customize the image during the build. The downside is the size of the image. It is the largest of the general-purpose SLE BCIs, so it is not always the best choice for a deployment image.\nA variant of BCI-Base called BCI-Init comes with systemd preinstalled. The BCI-Init container image can be useful in scenarios requiring systemd for managing services in a single container.\nBCI-Minimal: When you do not need Zypper This is a stripped-down version of the BCI-Base image. BCI-Minimal comes without Zypper, but it does have the RPM package manager installed. This significantly reduces the size of the image. However, while RPM can install and remove packages, it lacks support for repositories and automated dependency resolution. The BCI-Minimal image is therefore intended for creating deployment containers, and then installing the desired RPM packages inside the containers. Although you can install the required dependencies, you need to download and resolve them manually. However, this approach is not recommended as it is prone to errors.\nBCI-Micro: When you need to deploy static binaries This image is similar to BCI-Minimal but without the RPM package manager. The primary use case for the image is deploying static binaries produced externally or during multi-stage builds. As there is no straightforward way to install additional dependencies inside the container image, we recommend deploying a project using the BCI-Minimal image only when the final build artifact bundles all dependencies and has no external runtime requirements (like Python or Ruby).\nBCI-BusyBox: When you need the smallest and GPLv3-free image Similar to BCI-Micro, the BCI-BusyBox image comes with the most basic tools only. However, these tools are provided by the BusyBox project. This has the benefit of further size reduction. Furthermore, the image contains no GPLv3 licensed software. When using the image, keep in mind that there are certain differences between the BusyBox tools and the GNU Coreutils. So scripts written for a system that uses GNU Coreutils may require modification to work with BusyBox.\nApproximate sizes For your reference, the list below provides an approximate size of each SLE BCI. Keep in mind that the provided numbers are rough estimations.\nBCI-Base ~94 MB\nBCI-Minimal ~42 MB\nBCI-Micro ~26 MB\nBCI-BusyBox ~14 MB\n","description":"SUSE offers several general-purpose SLE Base Container Images that are intended as deployment targets or as foundations for creating customized images: BCI-Base, BCI-Minimal, BCI-Micro, and BCI-BusyBox. These images share the common SLES base, and none of them ship with a specific language or an application stack. All images feature the RPM database (even if the specific image does not include the RPM package manager) that can be used to verify the provenance of every file in the image."},{"id":2,"href":"/bci-docs/guides/use-with-golang/","title":"Building and Deploying Go Applications","parent":"Guides","content":" There is a SLE BCI that can be used with the Go programming language. There are a couple different recommended methods to work with the Go SLE BCI.\nDon’t Ship The Compiler Go is a compiled language producing a binary as the end result. That means the compiler does not need to be shipped as part of the images that are distributed. Instead, it is recommended that the Go image is used as the builder image only.\nBy not shipping the Go compiler with your application, the attack surface area of the containerized application is reduced and the overall image size is much smaller.\nUsing Go As A Builder Image There are two ways to work with Go images. First, you can encapsulate your application in a scratch container image, which is essentially an empty image. This approach will not function if your Go application depends on libc or any other library, as they will not be available.\nA second method is to use a slim base container image with just the minimal packages needed. The General Purpose SLE BCI images offer four different options here, depending on your exact requirements.\nBuilding from scratch The following Dockerfile illustrates building an application using the SLE BCI Go image to compile the binary and then copying it into a new image based on scratch. The example uses a hello world as the program name, which can be substituted for the real application name.\n# Build the Go Binary using the SLE BCI Go 1.19 images FROM registry.suse.com/bci/golang:1.19 as build WORKDIR /app COPY go.mod ./ COPY go.sum ./ RUN go mod download COPY *.go ./ # Make sure to build the application with CGO disabled. This will force Go to # use some Go implementations of code rather than those normally supplied by the # host operating system. You need this for scratch images as those supporting # libraries are not available. RUN CGO_ENABLED=0 go build -o /hello-world # Create image to bundle app FROM scratch COPY --from=build /hello-world /hello-world CMD [\u0026#34;/hello-world\u0026#34;] Additional settings like exposing network ports or running as a non-root user can be specified in the last step below the FROM scratch line.\nBuilding for SLE BCI Applications that require external libraries or CA certificates cannot be deployed into a scratch image. A General Purpose SLE BCI should be used instead. The above Dockerfile has to be slightly adjusted in this case:\n# Build the Go Binary using the SLE BCI Go 1.19 images FROM registry.suse.com/bci/golang:1.19 as build WORKDIR /app COPY go.mod ./ COPY go.sum ./ RUN go mod download COPY *.go ./ RUN go build -o /hello-world # Create image to bundle app FROM registry.suse.com/bci/bci-micro:15.4 # Install dependencies (if required) here COPY --from=build /hello-world /usr/local/bin/hello-world CMD [\u0026#34;/usr/local/bin/hello-world\u0026#34;] The above example uses the SLE BCI micro image as the deployment image for the resulting application. This is just one of the options, other options can be found in the section about the General Purpose SLE BCI.\n","description":"There is a SLE BCI that can be used with the Go programming language. There are a couple different recommended methods to work with the Go SLE BCI.\nDon’t Ship The Compiler Go is a compiled language producing a binary as the end result. That means the compiler does not need to be shipped as part of the images that are distributed. Instead, it is recommended that the Go image is used as the builder image only."},{"id":3,"href":"/bci-docs/guides/building-on-top-of-bci/","title":"Building Container Images based on SLE BCI","parent":"Guides","content":" Many tools for building container images exist in the ecosystem and our Base Container Images can be used by all of them. This guide summarizes the most important ones for our users:\nLocally using docker, podman, or nerdctl\nDocker or Podman in the Open Build Service\nKiwi in the Open Build Service\nUsing docker, podman and nerdctl The SLE Base Container Images are OCI compliant images and can thus be used without any modifications in your Dockerfile. Visit registry.suse.com, find the container image that fits your needs, and include it in the FROM line in your Dockerfile as follows:\nFROM registry.suse.com/bci/node:16 as node-builder WORKDIR /app/ COPY . /app/ RUN npm install \u0026amp;\u0026amp; npm run build Build it with your favorite container runtime: Docker docker build . Podman buildah bud --layers . nerdctl nerdctl build . Using the Open Build Service The Open Build Service can be used to build container images, as explained in the documentation. It supports building container images using Docker, Podman or kiwi.\nBuilding from a Dockerfile using docker or podman The Open Build Service supports building container images using a Dockerfile. However, you need to pay particular attention when creating offline builds with the Open Build Service. To build a container image based on SLE BCI follow the steps below.\nCreate a new package for a container image in an appropriate project where you have write access using osc:\n❯ cd /path/to/the/project/ ❯ osc mkpac my-container-image \u0026amp;\u0026amp; cd my-container-image Create a new repository for building container images for the project called containerfile by convention.\nCreate this repository by inserting the following XML snippet into the project settings via osc meta -e prj:\n\u0026lt;repository name=\u0026#34;containerfile\u0026#34;\u0026gt; \u0026lt;path project=\u0026#34;SUSE:Registry\u0026#34; repository=\u0026#34;standard\u0026#34;/\u0026gt; \u0026lt;path project=\u0026#34;SUSE:SLE-15-SP4:Update\u0026#34; repository=\u0026#34;standard\u0026#34;/\u0026gt; \u0026lt;arch\u0026gt;x86_64\u0026lt;/arch\u0026gt; \u0026lt;arch\u0026gt;aarch64\u0026lt;/arch\u0026gt; \u0026lt;arch\u0026gt;s390x\u0026lt;/arch\u0026gt; \u0026lt;arch\u0026gt;ppc64le\u0026lt;/arch\u0026gt; \u0026lt;/repository\u0026gt; Depending on the SLE version that you are targeting, you will have to adjust the version in line 3.\nAdd the following snippet into the project configuration. You can edit the project configuration via osc meta -e prjconf:\n%if %_repository == \u0026#34;containerfile\u0026#34; # if you prefer docker, use the following line or if you want to build using # podman, replace docker with podman Type: docker %endif Create a Dockerfile inside your the package my-container-image and set the base image of your container image using FROM as usual. The only difference is that you have to omit the registry.suse.com from the BCI URL and only use the build tag as illustrated below:\nbci-base FROM bci/bci-base:15.4 python FROM bci/python:3.10 openjdk FROM bci/openjdk:17 Set the build tags using comments in the Dockerfile. A build tag is the equivalent of the -t flag passed to docker build on the command line. Since the Open Build Service invokes docker build itself, it has to take the build tags from some other place and the Dockerfile is used for that as shown below:\n#!BuildTag: my-build-tag:latest #!BuildTag: my-build-tag:0.1 #!BuildTag: my-other-build-tag:0.6 Which is equivalent to invoking docker build as follows:\n❯ docker build -t my-build-tag:latest -t my-build-tag:0.1 -t my-other-build-tag:0.6 . Building a derived container image using kiwi kiwi is a generic image building tool that also supports building container images. It is tightly integrated into the Open Build Service as the standard image builder.\nBuilding a container image based on SLE BCI is outlined in the following steps:\nCreate a new package for your container image in an appropriate project where you have write access using osc:\n❯ cd /path/to/the/project/ ❯ osc mkpac my-kiwi-container \u0026amp;\u0026amp; cd my-kiwi-container Create a new repository for building container images for your project. Repositories building using kiwi are called images by convention and that name will be used below as well. If you pick a different repository name, be sure to adjust it in all other places as well.\nCreate this repository by inserting the following xml snippet into the project settings via osc meta -e prj:\n\u0026lt;repository name=\u0026#34;images\u0026#34;\u0026gt; \u0026lt;path project=\u0026#34;SUSE:Registry\u0026#34; repository=\u0026#34;standard\u0026#34;/\u0026gt; \u0026lt;path project=\u0026#34;SUSE:SLE-15-SP4:Update\u0026#34; repository=\u0026#34;standard\u0026#34;/\u0026gt; \u0026lt;arch\u0026gt;x86_64\u0026lt;/arch\u0026gt; \u0026lt;arch\u0026gt;aarch64\u0026lt;/arch\u0026gt; \u0026lt;arch\u0026gt;s390x\u0026lt;/arch\u0026gt; \u0026lt;arch\u0026gt;ppc64le\u0026lt;/arch\u0026gt; \u0026lt;/repository\u0026gt; Depending on the SLE version that you are targeting, you will have to adjust the version in line 3.\nAdd the following snippet into the project configuration. You can edit the project configuration via osc meta -e prjconf:\n%if \u0026#34;%_repository\u0026#34; == \u0026#34;images\u0026#34; Type: kiwi Repotype: none Patterntype: none Prefer: -libcurl4-mini Prefer: -systemd-mini Prefer: -libsystemd0-mini Prefer: -libudev-mini1 Prefer: -udev-mini Prefer: kiwi-boot-requires Prefer: sles-release Prefer: sles-release-MINI Prefer: python3-kiwi Preinstall: !rpm rpm-ndb Substitute: rpm rpm-ndb Binarytype: rpm %endif Create a kiwi.xml inside the package my-kiwi-image. Refer to a BCI using its build tag, where you prefix it with obsrepositories and replace the : with a # as outlined in the following examples:\nbci-base \u0026lt;image schemaversion=\u0026#34;6.5\u0026#34; name=\u0026#34;my-kiwi-image\u0026#34;\u0026gt; \u0026lt;description type=\u0026#34;system\u0026#34;\u0026gt;\u0026lt;!-- omitted --\u0026gt;\u0026lt;/description\u0026gt; \u0026lt;preferences\u0026gt; \u0026lt;type image=\u0026#34;docker\u0026#34; derived_from=\u0026#34;obsrepositories:/bci/bci-base#15.4\u0026#34;\u0026gt; \u0026lt;!-- remaining container settings here --\u0026gt; \u0026lt;/type\u0026gt; \u0026lt;/preferences\u0026gt; \u0026lt;!-- package \u0026amp; repository config here --\u0026gt; \u0026lt;/image\u0026gt; python \u0026lt;image schemaversion=\u0026#34;6.5\u0026#34; name=\u0026#34;my-kiwi-image\u0026#34;\u0026gt; \u0026lt;description type=\u0026#34;system\u0026#34;\u0026gt;\u0026lt;!-- omitted --\u0026gt;\u0026lt;/description\u0026gt; \u0026lt;preferences\u0026gt; \u0026lt;type image=\u0026#34;docker\u0026#34; derived_from=\u0026#34;obsrepositories:/bci/python#3.10\u0026#34;\u0026gt; \u0026lt;!-- remaining container settings here --\u0026gt; \u0026lt;/type\u0026gt; \u0026lt;/preferences\u0026gt; \u0026lt;!-- package \u0026amp; repository config here --\u0026gt; \u0026lt;/image\u0026gt; openjdk \u0026lt;image schemaversion=\u0026#34;6.5\u0026#34; name=\u0026#34;my-kiwi-image\u0026#34;\u0026gt; \u0026lt;description type=\u0026#34;system\u0026#34;\u0026gt;\u0026lt;!-- omitted --\u0026gt;\u0026lt;/description\u0026gt; \u0026lt;preferences\u0026gt; \u0026lt;type image=\u0026#34;docker\u0026#34; derived_from=\u0026#34;obsrepositories:/bci/openjdk#17\u0026#34;\u0026gt; \u0026lt;!-- remaining container settings here --\u0026gt; \u0026lt;/type\u0026gt; \u0026lt;/preferences\u0026gt; \u0026lt;!-- package \u0026amp; repository config here --\u0026gt; \u0026lt;/image\u0026gt; Set the build tags using comments in kiwi.xml:\n\u0026lt;!-- OBS-AddTag: my-build-tag:latest my-build-tag:0.1 my-other-build-tag:0.6 --\u0026gt; Building Container Images based on your own images You can build Container Images in the Open Build Service that are based on other Images that you have been build in the Build Service as well. Proceed for this as follows:\nSkip this step if your image is in the same project and repository as the image that you are building.\nFind the project and the repository corresponding to the container image that you would like to use as the base. You can leverage registry.opensuse.org for that by searching for container image and extracting the project and repository names (underlined in mint green and waterhole blue respectively):\nRuby SLE BCI on registry.opensuse.org Add this project and repository to your project’s repository configuration either by inserting a path entry via osc meta -e prj:\n\u0026lt;repository name=\u0026#34;my_container_build_repository\u0026#34;\u0026gt; \u0026lt;path project=\u0026#34;$THE_PROJECT_NAME\u0026#34; repository=\u0026#34;$THE_REPOSITORY_NAME\u0026#34;/\u0026gt; \u0026lt;!-- existing paths are here --\u0026gt; \u0026lt;!-- architectures --\u0026gt; \u0026lt;/repository\u0026gt; Alternatively, you can add this repository via the web interface. For that navigate to the project’s home page in the Open Build Service and click on the Repositories tab. There, find the repository in which you build your container image, click on the green plus icon and enter the project name and the repository name in the appearing popup:\nrepository view Use the build tag of the container image in the FROM instruction in your Dockerfile. The build tag can be found in the Dockerfile of the container image via the comment #!BuildTag: $TAG or in a kiwi xml description via the comment \u0026lt;!-- OBS-AddTag: $TAG -→.\nA simpler way is to go to registry.opensuse.org and find the container image. The path on registry.opensuse.org is constructed from the images project, repository and build tag as outlined in the image below (the project is underlined in mint green, the repository in waterhole blue and the build tag in persimmon):\nRuby SLE BCI on registry.opensuse.org with the build tag underlined ","description":"Many tools for building container images exist in the ecosystem and our Base Container Images can be used by all of them. This guide summarizes the most important ones for our users:\nLocally using docker, podman, or nerdctl\nDocker or Podman in the Open Build Service\nKiwi in the Open Build Service\nUsing docker, podman and nerdctl The SLE Base Container Images are OCI compliant images and can thus be used without any modifications in your Dockerfile."},{"id":4,"href":"/bci-docs/categories/","title":"Categories","parent":"Introduction to SLE Base Container Images","content":"","description":""},{"id":5,"href":"/bci-docs/documentation/","title":"Documentations","parent":"Introduction to SLE Base Container Images","content":"","description":""},{"id":6,"href":"/bci-docs/documentation/faq/","title":"Frequently Asked Questions","parent":"Documentations","content":" What? What has SUSE announced? SUSE Base Container Images (BCI) provides a repository of tested and certified container images based on SUSE Linux Enterprise Server. The container images are ready-to-go for enterprise use. SUSE maintains these images on a regular basis so you can use them worry-free. The images are updated with the latest security patches and features/functionalities are consistent with the base OS releases.\nWith Rancher 2.6, SUSE has announced full integration between Rancher and BCI while ensuring the latest security standards.\nWhat is the Base Container Image (BCI)? SUSE provides truly open, flexible, secure container images and application development tools for immediate use by developers, integrators, and operators.\nBCI images are available via the SUSE Container Registry and are free to use and distribute, in accordance with the EULA.\nWhat does the BCI include? BCI includes three sets of container images:\nPure SLE-based containers with a minimal set of packages: one with zypper, one without zypper but with rpm and one without both zypper and rpm, which adds flexibility to the development environment and removes unnecessary packages, making applications faster to deploy and to orchestrate.\nLanguage Stack Container Images with a base environment for programming languages including Python, Node.js, Ruby, .NET, ASP.Net, Java (based on OpenJDK), Go and Rust.\nApplication Stack Container Images provide ready to use containerized applications like RMT or PostgreSQL.\nWhat are the benefits of Base Container Image (BCI)? These are the main benefits:\nSupportability: While BCI images are free to use and redistribute, you can get support directly and leverage your applications at an enterprise level.\nAvailability: Base Container Images are available on x86-64, arch64, s390x, and ppc64le.\nSecurity: Enables more secure container images, reducing the number of notifications from container vulnerability scanners.\nWhat are the use cases for the Base Container Images (BCI)? BCI provides a stable, secure, and open ecosystem where you can develop and deploy applications in a light and flexible environment while leveraging your experience and the stability and security of the SLES (SUSE Linux Enterprise Server) operating system.\nFrom different perspectives, BCI offers several opportunities.\nRancher users:\nEnable Rancher to build using stable, reliable, secure, and certified enterprise components.\nLeverage SUSE’s in-house OS knowledge while containerizing applications as the tools will be the same and there is no migration path needed. For instance, from zypper to other packaging systems, BCI will behave as a container base as SLE would do for an OS.\nDevelopers:\nBCI can be deployed in any Linux host, helping migrations within a multi-vendor ecosystem, and avoiding vendor lock-in.\nFree BCI as an option in cases where a subscription is a hurdle in cloud-native environments\nISVs (Independent Software Vendors):\nISVs containerizing applications, using stable, reliable, secure, and certified enterprise OS.\nBCI offers ISVs a stable and performant ecosystem to build applications providing a secure supply chain.\nISVs need to run applications on a variety of hosts.\nWhat packages and libraries are available in BCI? SUSE provides several BCIs, which allows developers to choose which one fits their needs. At the same time, they provide developers with notable tools and libraries like compilers, crypto libraries, and several OS tools, to recap some of them.\nPackage managers and tools like zypper, rpm, sysctl or glibc.\nSeveral Libraries: lib-acl, lib-crypto, openssl, libldap, etc.\nWhat legal agreements are needed to build my products on BCI? You must accept the SLE BCI terms and conditions.\nWhy? Why did SUSE create Base Container Image (BCI)? We want to provide truly open, flexible, and secure container images and application development tools for immediate use by developers and integrators without the lock-in imposed by alternative offerings.\nTo match the needs of regulated markets, SUSE plans to provide a specifically hardened and certified SLE-based solution.\nOn which Hardware Platforms will BCI be available? BCIs are available on x86_64, aarch64, ppcle64 and s390x (.NET images are only available on x86-64)\nHow? Do I need a subscription to use BCI? No, you can use them without a subscription.\nBCI can be used for free, just pulling from the registry, they are ready to be used with no support.\nBCI under an active SLE subscription provides full support and access to SUSE repositories and a full set of tools and packages.\nDo I need a SUSE Linux environment to build images based on BCI? No, you can build and run BCI in any environment that supports building based on OCI compatible images.\nSee also Building on top of BCI.\nDo I need a SUSE Linux environment to deploy BCI? No, you can run BCI in any certified Kubernetes deployment or any OCI compatible runtime.\nCan I freely distribute applications built on BCI? There is no restriction to redistribute application based on the free BCI, as long as the repositories used are the free ones and no extra restriction applies to the packages on top of the image SUSE provides.\nThe restrictions also apply if the application includes binaries from SLES repositories. Adding third-party software implies restrictions at their respective layers.\nAll redistribution policies are listed in the EULA.\nCan I distribute my BCI-based container images without using SUSE’s registry? If BCI Images are free to use and distribute, you can use any registry to distribute your application based on BCI.\nCan I add non-BCI RPMs to a BCI image and still redistribute the resulting container image on a non-SUSE platform? As part of your development process, you can add non BCI-RPMs to the images, as everything added on top of the image offered is considered part of the application or dependencies.\nThere is no restriction from SUSE to redistribute the result if you comply with the EULA.\nIs BCI recommended for community projects? Yes, absolutely.\nWill BCI receive updates? Yes, we build BCI images leveraging the SUSE Linux Enterprise Server repository. We build new BCI images for each new SLE (SUSE Linux Enterprise) Service Pack and rebuild them when the included packages receive updates.\nWill my application built on BCI be supported? SUSE supports the available BCI images.\nApplications shipped via the container image should be supported by its vendor or developer.\nWhat is the BCI lifecycle? The General Purpose BCI follows the General Support lifecycle of the SLE Service Pack they are made for. The SUSE Linux Enterprise Server lifecycle can be found on suse.com/lifecycle.\nApplication and Language Stack BCI have a lifecycle that is tied to the respective application or language stack and not to the service pack of the underlying OS. For further details, consult the SUSE lifecycle page suse.com/lifecycle.\nBCI images are not supported in LTSS (Long Term Service Pack Support).\nDoes BCI let me distribute my container images anywhere I want? Yes, SUSE will never oversee what you do with your images and how you distribute them. BCIs are freely distributable, and you can also distribute your applications as you want if you comply with the EULA.\nCan I add non-BCI packages if something is missing from BCI? Yes, but SUSE is supporting BCI as it comes from our registry. Adding packages to BCI is considered part of the development process but is not directly supported by SUSE.\nWhere do I report bugs with BCI images? Customers and partners with a subscription can use the regular channels to report issues. Bugs can also be reported to bugzilla.suse.com.\nWhere do we get support for BCI images? Support for BCI is available with a SLE subscription. Reach out to SUSE for the details.\nQuestions and discussions can be posted to the SUSE Community.\nCan I request for packages to be added to the BCI images (SLE_BCI repo)? Please start a thread on the SUSE Community for consideration.\n","description":"What? What has SUSE announced? SUSE Base Container Images (BCI) provides a repository of tested and certified container images based on SUSE Linux Enterprise Server. The container images are ready-to-go for enterprise use. SUSE maintains these images on a regular basis so you can use them worry-free. The images are updated with the latest security patches and features/functionalities are consistent with the base OS releases.\nWith Rancher 2.6, SUSE has announced full integration between Rancher and BCI while ensuring the latest security standards."},{"id":7,"href":"/bci-docs/guides/","title":"Guides","parent":"Introduction to SLE Base Container Images","content":"","description":""},{"id":8,"href":"/bci-docs/guides/container-suseconnect/","title":"How to use container-suseconnect","parent":"Guides","content":" What is container-suseconnect? container-suseconnect is a plugin available in all Base Container Images that ship with Zypper. When the plugin detects the host’s SUSE Linux Enterprise Server registration credentials, it uses them to give the container access the SUSE Linux Enterprise repositories. This includes additional modules and previous package versions that are not part of the free SLE_BCI repository.\nHow to use container-suseconnect If you are running a registered SLES system with Docker, container-suseconnect automatically detects and uses the subscription, without requiring any action on your part.\nOn openSUSE systems with Docker, you must copy the files /etc/SUSEConnect and /etc/zypp/credentials.d/SCCcredentials from a registered SLES machine to your local machine. Note that the /etc/SUSEConnect file is required only if you are using RMT for managing your registration credentials.\nHow to use container-suseconnect on non-SLE hosts or with Podman, Buildah or with nerdctl You need a registered SLES system to use container-suseconnect on non-SLE hosts or with Podman, Buildah, or with nerdctl. This can be a physical machine, a virtual machine, or the bci-base container with SUSEConnect installed and registered.\nIf you don’t use RMT, copy /etc/zypp/credentials.d/SCCcredentials to the development machine. Otherwise, copy both the /etc/zypp/credentials.d/SCCcredentials and /etc/SUSEConnect files.\nYou can use the following command to obtain SCCcredentials (replace REGISTRATION_CODE with your SCC registration code)\nDocker docker run --rm registry.suse.com/suse/sle15:latest bash -c \\ \u0026#34;zypper -n in SUSEConnect; SUSEConnect --regcode REGISTRATION_CODE; \\ cat /etc/zypp/credentials.d/SCCcredentials\u0026#34; Podman podman run --rm registry.suse.com/suse/sle15:latest bash -c \\ \u0026#34;zypper -n in SUSEConnect; SUSEConnect --regcode REGISTRATION_CODE; \\ cat /etc/zypp/credentials.d/SCCcredentials\u0026#34; nerdctl nerdctl run --rm registry.suse.com/suse/sle15:latest bash -c \\ \u0026#34;zypper -n in SUSEConnect; SUSEConnect --regcode REGISTRATION_CODE; \\ cat /etc/zypp/credentials.d/SCCcredentials\u0026#34; If you are running a container based on a SLE BCI, mount SCCcredentials (and optionally /etc/SUSEConnect) in the correct destination. The following example shows how to mount SCCcredentials in the current working directory:\nDocker docker run -v /path/to/SCCcredentials:/etc/zypp/credentials.d/SCCcredentials \\ -it --pull=always registry.suse.com/bci/bci-base:latest Podman podman run -v /path/to/SCCcredentials:/etc/zypp/credentials.d/SCCcredentials \\ -it --pull=always registry.suse.com/bci/bci-base:latest nerdctl nerdctl run -v /path/to/SCCcredentials:/etc/zypp/credentials.d/SCCcredentials \\ -it --pull=always registry.suse.com/bci/bci-base:latest Do not copy the SCCcredentials and SUSEConnect files into the container image to avoid inadvertently adding them to the final image. Use secrets instead, as they are only available to a single layer and are not part of the built image. To do this, put a copy of SCCcredentials (and optionally SUSEConnect) somewhere on the file system and modify the RUN instructions that invoke Zypper as follows:\nFROM registry.suse.com/bci/bci-base:latest RUN --mount=type=secret,id=SUSEConnect \\ --mount=type=secret,id=SCCcredentials \\ zypper -n in fluxbox Docker and Buildah both support mounting secrets via the --secret flag as follows: Docker docker build --secret=id=SCCcredentials,src=/path/to/SCCcredentials \\ --secret=id=SUSEConnect,src=/path/to/SUSEConnect . Podman buildah bud --layers --secret=id=SCCcredentials,src=/path/to/SCCcredentials \\ --secret=id=SUSEConnect,src=/path/to/SUSEConnect . Adding modules into the container or container Image container-suseconnect allows you to automatically add SLE Modules into a container or container image. What modules are added is determined by the environment variable ADDITIONAL_MODULES that includes a comma-separated list of the module names. In a Dockerfile, this is done using the ENV directive as follows:\nFROM registry.suse.com/bci/bci-base:latest ENV ADDITIONAL_MODULES sle-module-desktop-applications,sle-module-development-tools RUN --mount=type=secret,id=SCCcredentials zypper -n in fluxbox \u0026amp;\u0026amp; zypper -n clean ","description":"What is container-suseconnect? container-suseconnect is a plugin available in all Base Container Images that ship with Zypper. When the plugin detects the host’s SUSE Linux Enterprise Server registration credentials, it uses them to give the container access the SUSE Linux Enterprise repositories. This includes additional modules and previous package versions that are not part of the free SLE_BCI repository.\nHow to use container-suseconnect If you are running a registered SLES system with Docker, container-suseconnect automatically detects and uses the subscription, without requiring any action on your part."},{"id":9,"href":"/bci-docs/guides/vscode-dev-containers/","title":"How To Use SLE BCIs As VScode Development Containers","parent":"Guides","content":" VS Code with the source mounted in a Development Container. The open terminal is a console within the container. Visual Studio Code has a feature called Development Containers. This is part of the built-in functionality to work with remote containers. The Language Stack SLE BCIs make a great choice to use as a development environment.\nWhy Use The SLE BCI In Development Containers There are two reasons the BCI language stack containers are useful for development.\nFirst, you develop in the same environment as when you use a Language Stack SLE BCI to build or run your application. Being able to develop and build or run your application in the same environment setup enables you to discover quirks and issues that are related to the way your application works in the environment.\nSecond, when you have a team of people working on an application, all developers will have the same environment to work in. Whether they are on Windows, macOS, or Linux their will be the same.\nDocker Socket Required VS Code creates the development containers using the Docker Engine and it communicates with it over the Docker socket. That means you need a Docker socket available on your system.\nRancher Desktop is our recommended app for working with containers. It is available for Windows, macOS, and Linux. Alternatively, you can use another tool such as Docker Desktop or the Docker Engine itself if you are using Linux.\nVS Code mounts your code from the local system inside the container. This works best when the container runtime is on your local system as opposed to remote. While possible to do this with the container runtime on a remote system, this guide does not cover running the development container on a remote machine.\nDevelopment Container Basics Development containers enable you to mount any folder inside a container where you can specify the environment. Debugging, extensions, and other features work with the code as it is mounted within the container rather than the location on the local file system.\nDevelopment Container Configuration The configuration for Development Containers is stored in a file named .devcontainer/devcontainer.json. When you open up a codebase with this configuration file present, VS Code will read the configuration and present you with an option to use a Development Container.\nThere are two ways to specify where to get the container from. You can point it at an image or you can point it at a Dockerfile to build the image from. Since VS Code needs some additional packages installed you can’t simply point it at a SLE BCI image.\nTo illustrate using the Dockerfile method we can look at a setup for the Go programming language. A Dockerfile placed in the .devcontainer directory would look like:\nFROM registry.suse.com/bci/golang:1.18 # Install tools needed by Visual Studio Code Remote Development Containers RUN zypper --non-interactive install -y tar git gzip VS Code needs git, gzip, and tar installed which are not present in the Go SLE BCI image by default.\nWhile this example is targeted at Go, it will work for other languages where there is a BCI language stack available.\nThis file needs to be referenced in the devcontainer/devcontainer.json file. For example, a devcontainer.json could look like the following:\n{ \u0026#34;name\u0026#34;: \u0026#34;Golang\u0026#34;, \u0026#34;build\u0026#34;: { \u0026#34;dockerfile\u0026#34;: \u0026#34;Dockerfile\u0026#34; } } If you open up a project with these files in them VS Code will prompt you to open them in a container as the image below illustrates.\nPop-up asking if you want to open the code within a Development Container. This example JSON configuration file is in its simplest form. You can learn more details about the additional configuration in the VS Code documentation for Development Containers.\n","description":"VS Code with the source mounted in a Development Container. The open terminal is a console within the container. Visual Studio Code has a feature called Development Containers. This is part of the built-in functionality to work with remote containers. The Language Stack SLE BCIs make a great choice to use as a development environment.\nWhy Use The SLE BCI In Development Containers There are two reasons the BCI language stack containers are useful for development."},{"id":10,"href":"/bci-docs/","title":"Introduction to SLE Base Container Images","parent":"","content":" SLE Base Container Image (SLE BCI) are minimal SUSE Linux Enterprise Server 15-based images that you can use to develop, deploy, and share applications. There are two types of SLE BCI:\nGeneral-purpose SLE BCI can be used for building custom container images and for deploying applications.\nLanguage stack SLE BCI provide minimal environments for developing and deploying applications in specific programming languages.\nIn addition to that, we will provide Application Container Images based on SLE BCI featuring popular containerized applications like Nginx, PostgreSQL, MariaDB and RMT.\nHighlights SLE BCI are fully compatible with SUSE Linux Enterprise Server, but they do not require a subscription to run and distribute them.\nSLE BCI automatically run in FIPS-compatible mode when the host operating system is running in FIPS mode.\nEach SLE BCI includes the RPM database, which makes it possible to audit the contents of the container image. You can use the RPM database to determine the specific version of the RPM package any given file belongs to. This allows you to ensure that a container image is not susceptible to known and already fixed vulnerabilities.\nAll SLE BCI (except for those without zypper) come with the container-suseconnect service. This gives containers that run on a registered SLES host access to the full SLES repositories. container-suseconnect is invoked automatically when you run zypper for the first time, and the service adds the correct SLES repositories into the running container. On an unregistered SLES host or on a non-SLES host, the service does nothing.\nGeneral-purpose SLE BCI There are four general purpose SLE BCI, and each container image comes with a minimum set of packages to keep its size low. You can use a general purpose SLE BCI either as a starting point for building custom container images, or as a platform for deploying specific software. For more information about general purpose SLE BCI, see here.\nLanguage stack SLE BCI Language stack SLE BCI are built on top of the BCI-Base general-purpose SLE BCI. Each container image comes with the zypper stack and the free SLE_BCI repository. Additionally, each image includes most common tools for building and deploying applications in the specific language environment. This includes tools like a compiler or interpreter as well as the language specific package manager. For more information about language stack SLE BCI, see here.\nImportant note on status and lifecycle All container images, except for bci-base, are currently classified as tech preview, and SUSE doesn’t provide official support for them. This information is visible on the web on registry.suse.com. In addition to that, it is also indicated via the com.suse.supportlevel label whether a container image still has the tech preview status. You can use the skopeo and jq utilities to check the status of the desired SLE BCI as follows:\n❯ skopeo inspect docker://registry.suse.com/bci/bci-micro:15.4 | jq \u0026#39;.Labels[\u0026#34;com.suse.supportlevel\u0026#34;]\u0026#39; \u0026#34;techpreview\u0026#34; ❯ skopeo inspect docker://registry.suse.com/bci/bci-base:15.4 | jq \u0026#39;.Labels[\u0026#34;com.suse.supportlevel\u0026#34;]\u0026#39; \u0026#34;l3\u0026#34; In the example above, the com.suse.supportlevel label is set to techpreview in the bci-micro container image, indicating that the image still has the tech preview status. The bci-base container image on the other hand is fully l3 supported. Unlike like the general purpose SLE BCI, the language stack SLE BCI may not follow the lifecycle of the SLE distribution: they are supported as long as the respective language stack receives support. In other words, new versions of SLE BCI (indicated by the OCI tags) may be released during the lifecycle of a SLE Service Pack, while older versions may become unsupported. Refer to suse.com/lifecycle to find out whether the container in question is still under support.\nGetting started The SLE BCI are available as OCI-compatible container images directly from registry.suse.com and can be used like any other container image. For example, using one of the general purpose containers:\nDocker ❯ docker run --rm -it registry.suse.com/bci/bci-base:15.4 grep \u0026#39;^NAME\u0026#39; /etc/os-release NAME=\u0026#34;SLES\u0026#34; Podman ❯ podman run --rm -it registry.suse.com/bci/bci-base:15.4 grep \u0026#39;^NAME\u0026#39; /etc/os-release NAME=\u0026#34;SLES\u0026#34; nerdctl ❯ nerdctl run --rm -it registry.suse.com/bci/bci-base:15.4 grep \u0026#39;^NAME\u0026#39; /etc/os-release NAME=\u0026#34;SLES\u0026#34; Alternatively, you can use SLE BCI in a Dockerfile as follows:\nFROM registry.suse.com/bci/bci-base:15.4 RUN zypper -n in python3 \u0026amp;\u0026amp; \\ echo \u0026#34;Hello Green World!\u0026#34; \u0026gt; index.html ENTRYPOINT [\u0026#34;/usr/bin/python3\u0026#34;, \u0026#34;-m\u0026#34;, \u0026#34;http.server\u0026#34;] EXPOSE 8000 You can then build container images using your favorite container runtime:\nDocker ❯ docker build . Sending build context to Docker daemon 2.048kB Step 1/4 : FROM registry.suse.com/bci/bci-base:15.4 ---\u0026gt; e34487b4c4e1 Step 2/4 : RUN zypper -n in python3 \u0026amp;\u0026amp; echo \u0026#34;Hello Green World!\u0026#34; \u0026gt; index.html ---\u0026gt; Using cache ---\u0026gt; 9b527dfa45e8 Step 3/4 : ENTRYPOINT [\u0026#34;/usr/bin/python3\u0026#34;, \u0026#34;-m\u0026#34;, \u0026#34;http.server\u0026#34;] ---\u0026gt; Using cache ---\u0026gt; 953080e91e1e Step 4/4 : EXPOSE 8000 ---\u0026gt; Using cache ---\u0026gt; 48b33ec590a6 Successfully built 48b33ec590a6 ❯ docker run -p 8000:8000 --rm -d 48b33ec590a6 575ad7edf43e11c2c9474055f7f6b7a221078739fc8ce5765b0e34a0c899b46a ❯ curl localhost:8000 Hello Green World! Podman ❯ buildah bud --layers . STEP 1/4: FROM registry.suse.com/bci/bci-base:15.4 STEP 2/4: RUN zypper -n in python3 \u0026amp;\u0026amp; echo \u0026#34;Hello Green World!\u0026#34; \u0026gt; index.html --\u0026gt; Using cache 8541a01ef66f1e43f850d30d756628fe301ae0ffe09dd3918d7e64d6e1788a3a --\u0026gt; 8541a01ef66 STEP 3/4: ENTRYPOINT [\u0026#34;/usr/bin/python3\u0026#34;, \u0026#34;-m\u0026#34;, \u0026#34;http.server\u0026#34;] --\u0026gt; Using cache 61cccdaa38aab5a44b0ef24935f4aa671f3231b611e0fa45c32ce869da6f9461 --\u0026gt; 61cccdaa38a STEP 4/4: EXPOSE 8000 --\u0026gt; Using cache 3e93a763b2d0a56ffe70429ca05a110288a868b46b92f47c1609a1129d058383 --\u0026gt; 3e93a763b2d 3e93a763b2d0a56ffe70429ca05a110288a868b46b92f47c1609a1129d058383 ❯ podman run --rm -d -p 8000:8000 3e93a763b2d0a56ffe70429ca05a110288a868b46b92f47c1609a1129d058383 e6115cbd37cf94781597cb7b8ade500951e7f4206b13102bdd9e603279378e17 ❯ curl localhost:8000 Hello Green World! ","description":"SLE Base Container Image (SLE BCI) are minimal SUSE Linux Enterprise Server 15-based images that you can use to develop, deploy, and share applications. There are two types of SLE BCI:\nGeneral-purpose SLE BCI can be used for building custom container images and for deploying applications.\nLanguage stack SLE BCI provide minimal environments for developing and deploying applications in specific programming languages.\nIn addition to that, we will provide Application Container Images based on SLE BCI featuring popular containerized applications like Nginx, PostgreSQL, MariaDB and RMT."},{"id":11,"href":"/bci-docs/documentation/language-stack-bci/","title":"Language stack SLE Base Container Images","parent":"Documentations","content":" If you have a working knowledge of containers, you will not have any difficulties using SLE BCIs. However, there are certain features that set SLE BCIs apart from similar offerings, like images based on Debian or Alpine Linux. And understanding the specifics can help you to get the most out of SLE BCIs in the shortest time possible.\nLanguage stack SLE BCIs Language stack SLE BCI are built on top of BCI-Base. Below is an overview of the available language stack SLE BCIs.\npython URL: registry.suse.com/bci/python\nTags: 3.6, 3.9, 3.10\nShips with the python3 version from the tag and pip3, curl, git tools.\nnode URL: registry.suse.com/bci/node\nTags: 12, 14, 16\nComes with nodejs version from the tag, npm and git. The yarn package manager can be installed with the npm install -g yarn command.\nopenjdk URL: registry.suse.com/bci/openjdk\nTags: 11, 17\nShips with the OpenJDK runtime. Designed for deploying Java applications.\nopenjdk-devel URL: registry.suse.com/bci/openjdk-devel\nTags: 11, 17\nIncludes the development part of OpenJDK in addition to the OpenJDK runtime. Instead of Bash, the default entry point is the jshell shell.\nruby URL: registry.suse.com/bci/ruby\nTags: 2.5\nA standard development environment based on Ruby 2.5, featuring ruby, gem and bundler as well as git and curl.\ngolang URL: registry.suse.com/bci/golang\nTags: 1.16, 1.17, 1.18\nShips with the go compiler version specified in the tag.\ndotnet-runtime URL: registry.suse.com/bci/dotnet-runtime\nTags: 3.1, 5.0, 6.0\nIncludes the .NET runtime from Microsoft and the Microsoft .NET repository.\ndotnet-aspnet URL: registry.suse.com/bci/dotnet-aspnet\nTags: 3.1, 5.0, 6.0\nShips with the ASP.NET runtime from Microsoft and the Microsoft .NET repository.\ndotnet-sdk URL: registry.suse.com/suse/dotnet-sdk\nTags: 3.1, 5.0, 6.0\nComes with the .NET and ASP.NET SDK from Microsoft as well as the Microsoft .NET repository.\nrust URL: registry.suse.com/bci/rust\nTags: 1.59, 1.60\nShips with the Rust compiler and the cargo package manager.\n","description":"If you have a working knowledge of containers, you will not have any difficulties using SLE BCIs. However, there are certain features that set SLE BCIs apart from similar offerings, like images based on Debian or Alpine Linux. And understanding the specifics can help you to get the most out of SLE BCIs in the shortest time possible.\nLanguage stack SLE BCIs Language stack SLE BCI are built on top of BCI-Base."},{"id":12,"href":"/bci-docs/guides/podman-generate-systemd/","title":"Launch Containers with Podman and Systemd","parent":"Guides","content":" Local Container Orchestration A container runtime makes it easy to launch an application distributed as a single container. But things get more complicated when you need to run applications consisting of multiple containers, or when it’s necessary to start the applications automatically on system boot and restart them after they crash. While container orchestration tools like Kubernetes are designed for that exact purpose, they are intended to be used for highly distributed and scalable systems with hundreds of nodes, and not for a single machine. systemd and Podman are much better suited for the single-machine scenario, as they do not add another layer complexity to your existing setup.\nOverview Starting with version 1.3.0, Podman supports creating systemd unit files with the podman generate systemd subcommand. The subcommand creates a systemd unit file, making it possible to control a container or pod via systemd. Using the unit file you can launch a container or pod on boot, automatically restart it if a failure occurs, and keep its logs in journald.\nCreating a new Systemd Unit File The following example uses a simple NGINX container:\n❯ podman run -d --name web -p 8080:80 docker.io/nginx c0148d8476418a2da938a711542c55efc09e4119909aea70e287465c6fb51618 Generating a systemd unit for the container can be done as follows:\n❯ podman generate systemd --name --new web # container-web.service # autogenerated by Podman 4.2.0 # Tue Sep 13 10:58:54 CEST 2022 [Unit] Description=Podman container-web.service Documentation=man:podman-generate-systemd(1) Wants=network-online.target After=network-online.target RequiresMountsFor=%t/containers [Service] Environment=PODMAN_SYSTEMD_UNIT=%n Restart=on-failure TimeoutStopSec=70 ExecStartPre=/bin/rm -f %t/%n.ctr-id ExecStart=/usr/bin/podman run \\ --cidfile=%t/%n.ctr-id \\ --cgroups=no-conmon \\ --rm \\ --sdnotify=conmon \\ --replace \\ -d \\ --name web \\ -p 8080:80 docker.io/nginx ExecStop=/usr/bin/podman stop --ignore --cidfile=%t/%n.ctr-id ExecStopPost=/usr/bin/podman rm -f --ignore --cidfile=%t/%n.ctr-id Type=notify NotifyAccess=all [Install] WantedBy=default.target Podman outputs a unit file to the console that can be put either into the user unit systemd directories (~/.config/systemd/user/ or /etc/systemd/user/) or into the system unit systemd directory (/etc/systemd/systtem) and control the container via systemd. The --new flag instructs Podman to recreate the container on a restart. This ensures that the systemd unit is self-contained, and it does not depend on external state. The --name flag allows you to assign a user-friendly name to the container: without it Podman uses container IDs instead of their names.\nTo control the container as a user unit, proceed as follows:\n❯ podman generate systemd --name --new --files web /home/user/container-web.service ❯ mv container-web.service ~/.config/systemd/user/ ❯ systemctl --user daemon-reload Now the container can be started via systemctl --user start container-web:\n❯ systemctl --user start container-web ❯ systemctl --user is-active container-web.service active Run the podman ps command to see the list of all running containers :\n❯ podman ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES af92743971d2 docker.io/library/nginx:latest nginx -g daemon o... 15 minutes ago Up 15 minutes ago 0.0.0.0:8080-\u0026gt;80/tcp web One of the benefits of managing the container via systemd is the ability to automatically restart the container if it crashes. You can simulate a crash by sending SIGKILL to the main process in the container:\n❯ podman ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 4c89582fa9cb docker.io/library/nginx:latest nginx -g daemon o... About a minute ago Up About a minute ago 0.0.0.0:8080-\u0026gt;80/tcp web ❯ kill -9 $(podman inspect --format \u0026#34;{{.State.Pid}}\u0026#34; web) ❯ podman ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 0b5be4493251 docker.io/library/nginx:latest nginx -g daemon o... 4 seconds ago Up 4 seconds ago 0.0.0.0:8080-\u0026gt;80/tcp web Note that the container is not restarted when it is stopped gracefully, e.g. via podman stop web. To always restart it, add the flag --restart-policy=always to podman generate systemd.\nUpdating container images Using the described approach means that the container image is never updated. You can solve the problem by adding the --pull=always flag to the ExecStart= entry in the unit file. But be aware that this increases the startup time of the container and updates the image on every restart. The latter also means that a container image update can make the container unavailable outside of a scheduled maintenance window due to a newly introduced bug.\nThe auto-update subcommand in Podman provides a possible solution. Add the label io.containers.autoupdate=registry to a container to make Podman pull a new version of the container image from the registry when running podman auto-update. This makes it possible to update all container images with a single command at a desired time, and without increasing the startup time of the systemd units.\nThe auto update feature can be enabled by adding the line --label \u0026#34;io.containers.autoupdate=registry\u0026#34; \\ to the ExecStart= entry of the container’s systemd unit file. for the NGINX example, modify ~/.config/systemd/user/container-web.service as follows:\nExecStart=/usr/bin/podman run \\ --cidfile=%t/%n.ctr-id \\ --cgroups=no-conmon \\ --rm \\ --sdnotify=conmon \\ --replace \\ -d \\ --name web \\ --label \u0026#34;io.containers.autoupdate=registry\u0026#34; \\ -p 8080:80 docker.io/nginx After reloading the daemons and restarting the container, perform a dry run of the update (it will most likely not report any updates):\n❯ podman auto-update --dry-run UNIT CONTAINER IMAGE POLICY UPDATED container-web.service 87d263489307 (web) docker.io/nginx registry false It is good practice to have external testing in place to make sure that image updates are generally safe to be deployed. If you are confident in the quality of our container image, you can let Podman automatically apply image updates periodically by enabling the podman-auto-update.timer:\n# just for the current user ❯ systemctl --user enable podman-auto-update.timer Created symlink /home/user/.config/systemd/user/timers.target.wants/podman-auto-update.timer → /usr/lib/systemd/user/podman-auto-update.timer. # or as root ❯ sudo systemctl enable podman-auto-update.timer Created symlink /etc/systemd/system/timers.target.wants/podman-auto-update.timer → /usr/lib/systemd/system/podman-auto-update.timer. Managing multiple containers Certain applications rely on more than one container to function, for example a web frontend, a backend server and a database. Docker compose is popular tool for deploying multi-container applications on a single machine. While Podman does not support the compose command natively, in most cases compose files can be ported to a Podman pod and multiple containers.\nThe following example deploys a Drupal and PostgreSQL container in a single pod and manages these via systemd units. First, create a new pod that exposes the Drupal web interface:\n❯ podman pod create -p 8080:80 --name drupal 736cab072c49e68ad368ba819e9117be13ef8fa048a2eb88736b5968b3a19a64 Once the pod has been created, launch the Drupal frontend and the PostgreSQL database inside it:\n❯ podman run -d --name drupal-frontend --pod drupal docker.io/drupal ffd2fbd6d445e63fb0c28abb8d25ced78f819211d3bce9d6174fe4912d89f0ca ❯ podman run -d --name drupal-pg --pod drupal \\ -e POSTGRES_DB=drupal \\ -e POSTGRES_USER=user \\ -e POSTGRES_PASSWORD=pass \\ docker.io/postgres:11 a4dc31b24000780d9ffd81a486d0d144c47c3adfbecf0f7effee24a00273fcde This results in three running containers: the Drupal web interface, the PostgreSQL database and the pod’s infrastructure container.\n❯ podman ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 2948fa1476c6 localhost/podman-pause:4.2.0-1660228937 2 minutes ago Up About a minute ago 0.0.0.0:8080-\u0026gt;80/tcp 736cab072c49-infra ffd2fbd6d445 docker.io/library/drupal:latest apache2-foregroun... About a minute ago Up About a minute ago 0.0.0.0:8080-\u0026gt;80/tcp drupal-frontend a4dc31b24000 docker.io/library/postgres:11 postgres 40 seconds ago Up 41 seconds ago 0.0.0.0:8080-\u0026gt;80/tcp drupal-pg Creating a systemd unit for the pod is done similar to a single container:\n❯ podman generate systemd --name --new --files drupal /home/user/pod-drupal.service /home/user/container-drupal-frontend.service /home/user/container-drupal-pg.service ❯ mv *service ~/.config/systemd/user/ ❯ systemctl daemon-reload --user Since Podman is aware of which containers belong to the drupal pod and how their systemd units are called, it can correctly add the dependencies to the pod’s unit file. This means that when you start or stop the pod, systemd ensures that all containers inside the pod are started or stopped automatically.\nTo check systemd’s dependency handling, first stop the drupal pod and verify that no containers are currently running on the host:\n❯ podman pod stop drupal 736cab072c49e68ad368ba819e9117be13ef8fa048a2eb88736b5968b3a19a64 ❯ podman pod rm drupal 736cab072c49e68ad368ba819e9117be13ef8fa048a2eb88736b5968b3a19a64 ❯ podman ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES Start the drupal pod via systemctl start --user pod-drupal.service, and systemd launches the containers inside the pod:\n❯ systemctl start --user pod-drupal.service ❯ podman ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES d1589d3ac68b localhost/podman-pause:4.2.0-1660228937 5 seconds ago Up 5 seconds ago 0.0.0.0:8080-\u0026gt;80/tcp ca41b505bd13-infra a49bea53c20c docker.io/library/postgres:11 postgres 4 seconds ago Up 5 seconds ago 0.0.0.0:8080-\u0026gt;80/tcp drupal-pg dc9dca018dad docker.io/library/drupal:latest apache2-foregroun... 4 seconds ago Up 5 seconds ago 0.0.0.0:8080-\u0026gt;80/tcp drupal-frontend ","description":"Local Container Orchestration A container runtime makes it easy to launch an application distributed as a single container. But things get more complicated when you need to run applications consisting of multiple containers, or when it’s necessary to start the applications automatically on system boot and restart them after they crash. While container orchestration tools like Kubernetes are designed for that exact purpose, they are intended to be used for highly distributed and scalable systems with hundreds of nodes, and not for a single machine."},{"id":13,"href":"/bci-docs/tags/","title":"Tags","parent":"Introduction to SLE Base Container Images","content":"","description":""},{"id":14,"href":"/bci-docs/guides/using-sle-bci/","title":"Using SLE BCI","parent":"Guides","content":" Package manager The default package manager in SUSE Linux Enterprise is Zypper. Similar to APT in Debian and APK in Alpine Linux, Zypper offers a command-line interface for all package management tasks. Below is brief overview of commonly used container-related Zypper commands.\nInstall packages zypper --non-interactive install $PACKAGE_NAME Add a repository zypper --non-interactive addrepo $REPOSITORY_URL; zypper --non-interactive refresh Update all packages zypper --non-interactive update Remove a package zypper --non-interactive remove --clean-deps $PACKAGE_NAME the --clean-deps flag ensures that no longer required dependencies are removed as well\nClean up temporary files zypper clean For more information on using Zypper, refer to the zypper documentation.\nAll the described commands use the --non-interactive flag to skip confirmations, since you cannot approve these manually during container builds. Keep in mind that you must use the flag with any command that modifies the system. Also note that --non-interactive is not a \u0026#34;yes to all\u0026#34; flag. Instead, --non-interactive confirms what is considered to be the intention of the user. For example, an installation command with the --non-interactive option fails if it needs to import new repository signing keys, as that is something that the user should verify themselves.\nCommon patterns Here are a few examples that can give you an idea how to accomplish certain tasks in SLE BCI compared to Debian.\nRemove orphaned packages Debian: apt-get autoremove -y\nSLE BCI: Not required as long as you remove installed packages using the zypper --non-interactive remove --clean-deps $PACKAGE_NAME\nObtain container’s architecture Debian: dpkgArch=\u0026#34;$(dpkg --print-architecture | awk -F- \u0026#39;{ print $NF }\u0026#39;)\u0026#34;\nSLE BCI: arch=\u0026#34;$(uname -p|sed \u0026#39;s/x86_64/amd64/\u0026#39;)\u0026#34;\nInstall packages required for compilation Debian: apt-get install -y build-essential\nSLE BCI: zypper -n in gcc gcc-c++ make\nVerify GnuPG signatures Debian: gpg --batch --verify $SIGNATURE_URL $FILE_TO_VERIFY\nSLE BCI: zypper -n in dirmngr; gpg --batch --verify $SIGNATURE_URL $FILE_TO_VERIFY; zypper -n remove --clean-deps dirmngr; zypper -n clean\nPackage naming conventions SUSE Linux Enterprise package naming conventions differ from Debian, Ubuntu, and Alpine, and they are closer to those of Red Hat Enterprise Linux. The main difference is that development packages of libraries (that is, packages containing headers and build description files) are named $PACKAGE-devel in SUSE Linux Enterprise, as opposed to $PACKAGE-dev as they are in Debian and Ubuntu. When in doubt, search for the package directly using the following command:\nDocker docker run --rm registry.suse.com/bci/bci-base:$OS_VERSION zypper search $PACKAGE_NAME Podman podman run --rm registry.suse.com/bci/bci-base:$OS_VERSION zypper search $PACKAGE_NAME nerdctl nerdctl run --rm registry.suse.com/bci/bci-base:$OS_VERSION zypper search $PACKAGE_NAME (replace OS_VERSION with the appropriate service version number, for example: 15.3 or 15.4).\nAdding GPG signing keys Adding external repositories to a container or container image normally requires importing the GPG key used for signing the packages. This can be done with the rpm --import $KEY_URL command. This adds the key to the RPM database, and all packages from the repository can be installed afterwards.\n","description":"Package manager The default package manager in SUSE Linux Enterprise is Zypper. Similar to APT in Debian and APK in Alpine Linux, Zypper offers a command-line interface for all package management tasks. Below is brief overview of commonly used container-related Zypper commands.\nInstall packages zypper --non-interactive install $PACKAGE_NAME Add a repository zypper --non-interactive addrepo $REPOSITORY_URL; zypper --non-interactive refresh Update all packages zypper --non-interactive update Remove a package zypper --non-interactive remove --clean-deps $PACKAGE_NAME the --clean-deps flag ensures that no longer required dependencies are removed as well"},{"id":15,"href":"/bci-docs/guides/verify-with-cosign/","title":"Verify SLE Base Container Images With Cosign","parent":"Guides","content":" Introduction Verifying container images allows you to confirm their provenance, thus ensuring the supply chain security. As an alternative to the existing solutions, it is possible to use Cosign for verifying container images.\nVerifying SLE BCI with Cosign To verify a SLE BCI image, run Cosign in the container. The command below fetches the signing key from the SUSE server and uses it to verify the latest BCI-Base container image.\n\u0026gt; podman run --rm -it gcr.io/projectsigstore/cosign verify \\ --key https://ftp.suse.com/pub/projects/security/keys/container–key.pem \\ registry.suse.com/bci/bci-base:latest | tail -1 | jq [ { \u0026#34;critical\u0026#34;: { \u0026#34;identity\u0026#34;: { \u0026#34;docker-reference\u0026#34;: \u0026#34;registry.suse.com/bci/bci-base\u0026#34; }, \u0026#34;image\u0026#34;: { \u0026#34;docker-manifest-digest\u0026#34;: \u0026#34;sha256:52a828600279746ef669cf02a599660cd53faf4b2430a6b211d593c3add047f5\u0026#34; }, \u0026#34;type\u0026#34;: \u0026#34;cosign container image signature\u0026#34; }, \u0026#34;optional\u0026#34;: { \u0026#34;creator\u0026#34;: \u0026#34;OBS\u0026#34; } } ] The signing key can be used to verify all SLE BCI container images, and it also ships with SLE 15 (the /usr/share/container-keys/suse-container-key.pem file).\nYou can also check SLE BCI container images against rekor, the immutable tamper resistant ledger. For example:\n\u0026gt; podman run --rm -it -e COSIGN_EXPERIMENTAL=1 gcr.io/projectsigstore/cosign \\ verify --key https://ftp.suse.com/pub/projects/security/keys/container–key.pem \\ registry.suse.com/bci/bci-base:latest | tail -1 | jq [ { \u0026#34;critical\u0026#34;: { \u0026#34;identity\u0026#34;: { \u0026#34;docker-reference\u0026#34;: \u0026#34;registry.suse.com/bci/bci-base\u0026#34; }, \u0026#34;image\u0026#34;: { \u0026#34;docker-manifest-digest\u0026#34;: \u0026#34;sha256:52a828600279746ef669cf02a599660cd53faf4b2430a6b211d593c3add047f5\u0026#34; }, \u0026#34;type\u0026#34;: \u0026#34;cosign container image signature\u0026#34; }, \u0026#34;optional\u0026#34;: { \u0026#34;creator\u0026#34;: \u0026#34;OBS\u0026#34; } } ] If verification fails, the output of the cosign verify command is similar to the one below.\nError: no matching signatures: crypto/rsa: verification error main.go:62: error during command execution: no matching signatures: crypto/rsa: verification error ","description":"Introduction Verifying container images allows you to confirm their provenance, thus ensuring the supply chain security. As an alternative to the existing solutions, it is possible to use Cosign for verifying container images.\nVerifying SLE BCI with Cosign To verify a SLE BCI image, run Cosign in the container. The command below fetches the signing key from the SUSE server and uses it to verify the latest BCI-Base container image."},{"id":16,"href":"/bci-docs/documentation/why-sle-bci/","title":"Why SLE Base Container Images","parent":"Documentations","content":" SLE BCIs offer a platform for creating SLE-based custom container images and containerized applications that can be distributed freely. SLE BCIs feature the same predictable enterprise lifecycle as SLES. The SLE_BCI 15 SP3 and SP4 repository (which is a subset of the SLE repository) gives SLE BCIs access to 4,000 packages available for the AMD64/Intel 64, AArch64, ppc64le, and s390x architectures. The packages in the repository have undergone quality assurance and security audits by SUSE. The container images are FIPS-compliant when running on a host in FIPS mode. In addition to that, SUSE can provide official support for SLE BCIs through SUSE subscription plans.\nSecurity Each package in the SLE_BCI repository undergoes security audits, and SLE BCIs benefit from the same mechanism of dealing with CVEs as SLES. All discovered and fixed vulnerabilities are announced via e-mail, the dedicated CVE pages, and as OVAL and CVRF data. To ensure a secure supply chain, all container images are signed with Notary v1, Podman’s GPG signatures, and Sigstore Cosign.\nStability Since SLE BCIs are based on SLE, they feature the same level of stability and quality assurance as SUSE Linux Enterprise Server. Similar to SLES, SLE BCIs receive maintenance updates that provide bug fixes, improvements, and security patches.\nTooling and integration SLE BCIs are designed to provide drop-in replacements for popular container images available on hub.docker.com. You can use the general-purpose SLE BCIs and the tools they put at your disposal to create custom container images, while the language stack SLE BCIs provide a foundation and the required tooling for building containerized applications.\nRedistribution SLE BCIs are covered by a permissive EULA that allows you to redistribute custom container images based on a SLE BCI.\n","description":"SLE BCIs offer a platform for creating SLE-based custom container images and containerized applications that can be distributed freely. SLE BCIs feature the same predictable enterprise lifecycle as SLES. The SLE_BCI 15 SP3 and SP4 repository (which is a subset of the SLE repository) gives SLE BCIs access to 4,000 packages available for the AMD64/Intel 64, AArch64, ppc64le, and s390x architectures. The packages in the repository have undergone quality assurance and security audits by SUSE."}]